{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlE8jTJvwotFKyDzGArDHs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelSylvi/fyp_send_prototype/blob/main/Send_Prot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ni6VakNxz8kN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6f44c8-f203-4a89-950d-e2dd9d967bd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.43.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.10)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio transformers gtts pytesseract Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgnEgd22-xfO",
        "outputId": "7f02f0e0-69f9-4c73-a1dc-2e0e45c73469"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (185.125.190.81)] [Connected to cloud.r-p\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\r                                                                               \rHit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "from gtts import gTTS\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "UAYZVc40-xia"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8P3Hqim-xlZ",
        "outputId": "3bdae7c8-f9e7-4485-ac70-3fb17047cc4f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text-to-Speech function\n",
        "def text_to_speech(text, lang='en'):\n",
        "    \"\"\"Converts text to an audio file and returns the path.\"\"\"\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    temp_file = \"temp_audio.mp3\"\n",
        "    tts.save(temp_file)\n",
        "    return temp_file"
      ],
      "metadata": {
        "id": "xVhC0aWz-xoS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No need to import the pipeline for this function.\n",
        "# Keep `from gtts import gTTS` and `import random`\n",
        "\n",
        "def buddy_chat_logic(user_input):\n",
        "    \"\"\"\n",
        "    Handles the chat input using simple keyword matching for a guaranteed response.\n",
        "    \"\"\"\n",
        "    if not user_input or user_input.strip() == \"\":\n",
        "        return \"Hey there! What would you like to ask me?\", None\n",
        "\n",
        "    user_input_lower = user_input.lower()\n",
        "\n",
        "    response_text = \"That's an interesting question! Let's explore that together.\"\n",
        "\n",
        "    # Simple keyword-based logic\n",
        "    if \"good morning\" in user_input_lower or \"hi\" in user_input_lower or \"hello\" in user_input_lower:\n",
        "        response_text = \"Hi there! I'm so happy to see you. How are you today?\"\n",
        "    elif \"sad\" in user_input_lower or \"unhappy\" in user_input_lower or \"crying\" in user_input_lower or \"frustrated\" in user_input_lower:\n",
        "        response_text = \"It sounds like you're feeling a little down. It's okay. Let's take a break with a silly sound!\"\n",
        "        silly_things = [\"Boing!\", \"Zzzzz!\", \"Wibble wobble!\"]\n",
        "        response_text += \" \" + random.choice(silly_things)\n",
        "    elif \"happy\" in user_input_lower or \"excited\" in user_input_lower or \"wonderful\" in user_input_lower:\n",
        "        response_text = \"That sounds wonderful! I'm so happy for you! Let's read a story about that!\"\n",
        "    elif \"mean\" in user_input_lower:\n",
        "        response_text = \"I can help with that! A word's meaning is what it's trying to say. For example, 'cat' means a furry animal that purrs!\"\n",
        "\n",
        "    # Return the text and the audio file path\n",
        "    try:\n",
        "        audio_path = text_to_speech(response_text)\n",
        "        return response_text, audio_path\n",
        "    except Exception as e:\n",
        "        # This catch is for the gTTS library, which can also fail.\n",
        "        print(f\"Error during audio generation: {e}\")\n",
        "        return response_text, None # Return the text without audio\n",
        "\n",
        "# --- The rest of your code remains the same ---\n",
        "# ..."
      ],
      "metadata": {
        "id": "WjTXXrJ4-xrT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_detective_logic(image_input):\n",
        "    \"\"\"\n",
        "    Performs OCR on an image and returns the detected text.\n",
        "    \"\"\"\n",
        "    if image_input is None:\n",
        "        return \"Please upload an image to detect words.\", None\n",
        "\n",
        "    try:\n",
        "        # Perform OCR\n",
        "        text_from_image = pytesseract.image_to_string(image_input)\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}. Please try a different image.\", None\n",
        "\n",
        "    response_text = \"\"\n",
        "    if text_from_image.strip() == \"\":\n",
        "        response_text = \"I couldn't find any words in that picture. Let's try another one!\"\n",
        "    else:\n",
        "        response_text = f\"I found these words: {text_from_image}\"\n",
        "\n",
        "    audio_path = text_to_speech(response_text)\n",
        "    return response_text, audio_path\n"
      ],
      "metadata": {
        "id": "RAlwASuv-xtx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def magic_camera_logic(image_input):\n",
        "    \"\"\"\n",
        "    Identifies the main object in an image and provides a related phonics story.\n",
        "    \"\"\"\n",
        "    if image_input is None:\n",
        "        return \"Please upload an image for me to see!\", None\n",
        "\n",
        "    # Use the pre-trained object classifier\n",
        "    predictions = object_classifier(image_input)\n",
        "\n",
        "    # Get the top prediction\n",
        "    main_object = predictions[0]['label']\n",
        "\n",
        "    # Simple logic for phonics story\n",
        "    first_letter = main_object[0].upper()\n",
        "    story = f\"Aha! I see a {main_object}! '{first_letter}' is for {main_object}! Can you say '{first_letter}'? Now let's find another word that starts with that sound.\"\n",
        "\n",
        "    audio_path = text_to_speech(story)\n",
        "    return story, audio_path"
      ],
      "metadata": {
        "id": "4r4cKGBxBId4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emotion_and_attention_logic(error_count, time_on_task):\n",
        "    \"\"\"\n",
        "    This function simulates the on-device tracking for a Gradio demo.\n",
        "    \"\"\"\n",
        "    error_count = int(error_count)\n",
        "    time_on_task = int(time_on_task)\n",
        "\n",
        "    response_text = \"Everything looks good! Keep up the great work!\"\n",
        "\n",
        "    # Simple rule-based logic to simulate the \"check-in\"\n",
        "    if error_count > 3:\n",
        "        response_text = \"It seems like you're getting a little stuck. Let's take a break and breathe together. Would you like to try a calming game?\"\n",
        "    elif time_on_task > 120: # 2 minutes\n",
        "        response_text = \"You've been working hard for a while now! How about we do something different for a bit?\"\n",
        "\n",
        "    audio_path = text_to_speech(response_text)\n",
        "    return response_text, audio_path, 0, 0 # Reset counters after check-in"
      ],
      "metadata": {
        "id": "7XrgQ9WqBKK5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Gradio Interface (The UI part) ---\n",
        "\n",
        "with gr.Blocks(title=\"Buddy's AI Reading App\") as demo:\n",
        "    gr.Markdown(\"# Buddy's AI Reading App\")\n",
        "    gr.Markdown(\"Welcome to your personal reading pal! Let's explore some features.\")\n",
        "\n",
        "    # --- 1. Buddy's Storyteller Chat ---\n",
        "    with gr.Tab(\"Buddy's Chat\"):\n",
        "        chat_message = gr.Textbox(label=\"Talk to Buddy\")\n",
        "        chat_output = gr.Textbox(label=\"Buddy says:\")\n",
        "        audio_output_chat = gr.Audio(label=\"Buddy's Voice\", autoplay=True)\n",
        "        chat_button = gr.Button(\"Send Message\")\n",
        "        chat_button.click(\n",
        "            fn=buddy_chat_logic,\n",
        "            inputs=chat_message,\n",
        "            outputs=[chat_output, audio_output_chat]\n",
        "        )\n",
        "\n",
        "    # --- 2. The Word Detective Game ---\n",
        "    with gr.Tab(\"Word Detective\"):\n",
        "        with gr.Row():\n",
        "            image_input_wd = gr.Image(type=\"pil\", label=\"Upload a picture of a page\")\n",
        "            output_text_wd = gr.Textbox(label=\"Words I Found:\")\n",
        "        output_audio_wd = gr.Audio(label=\"Buddy Reads\", autoplay=True)\n",
        "        detect_button = gr.Button(\"Detect Words!\")\n",
        "        detect_button.click(\n",
        "            fn=word_detective_logic,\n",
        "            inputs=image_input_wd,\n",
        "            outputs=[output_text_wd, output_audio_wd]\n",
        "        )\n",
        "\n",
        "    # --- 3. Buddy's Magic Camera ---\n",
        "    with gr.Tab(\"Magic Camera\"):\n",
        "        with gr.Row():\n",
        "            image_input_mc = gr.Image(type=\"pil\", label=\"Upload a picture of an object\")\n",
        "            output_text_mc = gr.Textbox(label=\"Buddy's Story:\")\n",
        "        output_audio_mc = gr.Audio(label=\"Buddy's Voice\", autoplay=True)\n",
        "        camera_button = gr.Button(\"What is this?\")\n",
        "        camera_button.click(\n",
        "            fn=magic_camera_logic,\n",
        "            inputs=image_input_mc,\n",
        "            outputs=[output_text_mc, output_audio_mc]\n",
        "        )\n",
        "\n",
        "    # --- 4. \"How Are You Feeling?\" Check-in ---\n",
        "    with gr.Tab(\"Feeling Check-in\"):\n",
        "        gr.Markdown(\"This feature simulates how Buddy tracks your feelings and attention.\")\n",
        "        error_counter = gr.Number(value=0, label=\"Mistakes Made\")\n",
        "        time_counter = gr.Number(value=0, label=\"Seconds Spent on Task\")\n",
        "        output_text_feel = gr.Textbox(label=\"Buddy's Check-in:\")\n",
        "        output_audio_feel = gr.Audio(label=\"Buddy's Voice\", autoplay=True)\n",
        "        checkin_button = gr.Button(\"How am I doing, Buddy?\")\n",
        "        checkin_button.click(\n",
        "            fn=emotion_and_attention_logic,\n",
        "            inputs=[error_counter, time_counter],\n",
        "            outputs=[output_text_feel, output_audio_feel, error_counter, time_counter]\n",
        "        )\n",
        ""
      ],
      "metadata": {
        "id": "d0R3bJ49BWJM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the app!\n",
        "# The share=True parameter is what makes it publicly accessible.\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "MSsXW2tJBKmK",
        "outputId": "bb91fe7c-2523-454d-deaa-974457cb7114"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://675140926404130764.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://675140926404130764.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}